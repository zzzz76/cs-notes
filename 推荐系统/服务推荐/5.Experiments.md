# 5 Experiments

在本节中，我们将在真实世界的Web服务质量数据集上进行广泛的实验来评估NBMF的性能。实验旨在解决以下问题：（1）NBMF方法与其他最先进的Qos预测方法相比如何？（2）网络偏置的权重 $\alpha$ 如何影响预测精度？（3）潜在特征向量的维度 $d$ 如何影响预测精度？（4）质量矩阵的稀疏程度如何影响预测精度？我们在python3.7中实现了我们的NBMF方法以及所有的基线方法，所有的实验都是在一台装有Intel i5-10400 2.9 GHz CPU 和 8GB内存的Linux服务器上进行的，运行64位Ubuntu 16.04。请注意，所有的源代码都已公开发布，可进行可重复的研究。

## 5.1 Dataset

为了评估本文方法的有效性，我们采用真实的Web服务数据集 WSDream 作为测试数据集[29]。如表2所示，该数据集包括 1974675 条Qos记录，这些记录是通过分布在137个自治域的 339 台计算机（用户）对分布在991个自治域的5825个 Web 服务进行调用得到的。每个用户和每个 Web 服务之间都有一条通过调用产生的Qos记录，在本文中，我们主要研究了Qos属性中的响应时间（RT）。同时，该数据集中还收集了这些用户和服务的IP、国家等信息。关于这个数据集的更多细节可以在[7]中找到。

![image-20220213012743620](image-20220213012743620.png)

## 5.2 Evaluation Metrics

为了评估本文方法的预测性能，我们采用平均绝对误差 (MAE) 和均方根误差 (RMSE) 作为评测指标，通过计算预测的Qos值与实际Qos值之间的偏差来度量预测的准确性。

MAE 的定义为：
$$
MAE = \cfrac{1}{N}\sum_{u,i} \vert Q_{ij} - \hat{Q}_{ij} \vert
$$
RMSE 的定义为：
$$
RMSE = \sqrt{\cfrac{1}{N}\sum_{u, i}(Q_{ij} - \hat{Q}_{ij})^2}
$$
其中，$Q_{ij}$ 和 $\hat{Q}_{ij}$ 分别表示用户 $i$ 调用服务 $j$ 的Qos真实值和预测值， $N$  表示预测的Qos值数量。从公式可以观察到 RMSE 对较大的误差反应比较敏感。。MAE 和 RMSE 的范围从 0到无限，它们的值越小表示预测方法的预测性能越好。

## 5.3 Accuracy Comparison

为了展示我们的NBMF方法的预测准确性，我们重新实现了7种最具代表性的Qos预测方法（包括两种也利用位置信息的最先进的基于MF的方法），并将NBMF方法与它们进行比较。以下是这些方法的简要介绍：

1）UMEAN：这种方法用目标用户的已知Qos值的平均值来预测该用户从未调用过的服务的QoS值。

2）IMEAN：这种方法用目标服务的已知Qos值的平均值来预测从未调用过该服务的用户的QoS值。

3）UIPCC：这种方法结合了基于用户和基于项目的协同过滤方法，它采用相似用户和相似服务来预测QoS值。

4）PMF：这种方法是基于概率的矩阵分解方法，它把矩阵分解为用户潜在特征矩阵和项目潜在特征矩阵来预测Qos值。

5）BMF：这种方法扩展了基于概率的矩阵分解方法，它用用户偏置和服务偏置来改进矩阵分解模型。

6）LBR2：这种方法首次使用额外的用户信息来协助预测，它用基于地理位置的正则化项来改进矩阵分解模型。

7）HMF：这种方法使用额外的用户和服务信息来协助预测，它用基于地理位置的聚类方法来改进矩阵分解模型。

8）NBMF：这种方法扩展了基于偏置的矩阵分解方法，它用基于网络的用户偏置和服务偏置来改进矩阵分解模型。

在现实世界中，用户服务矩阵通常非常稀疏，因为用户通常只调用过少量的Web服务。因此在本文中，为了模拟不同稀疏程度的矩阵环境，我们从数据集中随机删除一定数量的Qos值，生成密度为10%、15%、20%、25% 和 30% 的用户服务矩阵。例如，矩阵密度为10%意味着我们随机选择原始用户服务矩阵中10%的Qos值来预测其余90%的Qos值。移除的原始Qos值用作预期值，以评估不同方法所取得的预测精度。

在实验中，基线方法的参数被初始化为相应论文中的参数，然后被仔细调整以达到最佳性能。我们的NBMF方法参数被设置为 $\alpha = 0.2$， $d = 10$，$\lambda_u = \lambda_w = \lambda_b = \lambda_p = 0.02$，$\eta_u = \eta_w = \eta_b = \eta_p = 0.003$，矩阵分解过程中的最大迭代次数被设置为300次。此外，我们在模型的训练过程中执行早期停止策略，如果测试集上的RMSE连续5次增加，我们就停止训练。

表3提供了不同的方法在10%至30%矩阵密度下的预测精度。我们可以观察到，与其它较经典的预测方法相比，NBMF在MAE上实现了2.16∼47.05％的改进，在RMSE上实现了2.76∼38.74％的改进，本文提出的方法无论在何种矩阵密度下均具有更小的MAE和RMSE，这表明本文的方法具有最高的预测精度。与BMF方法相比，我们的NBMF方法在MAE和RMSE上分别实现了6.81%和4.49%的改进。因为现实世界中的网络环境是非常复杂的，比起单纯的用户偏置和服务偏置，考虑基于网络的用户偏置和服务偏置要更加适用于真实的服务推荐系统。与HMF方法相比，我们的NBMF方法在MAE和RMSE上分别实现了2.16%和2.76%的改进。这是因为，HMF方法根据区域进行聚类，而NBMF方法根据通信路径进行聚类，对于复杂的网络环境具备很好的适应性。随着矩阵密度从10%增加到30%，所有方法的预测精度都显著提高。这表明，更多的质量信息可以促进更高的预测精度。



![image-20220216133459406](image-20220216133459406.png)



## 5.4 Impact of Parameter $\alpha$

在我们的分层矩阵分解模型中，参数α控制我们在QoS预测程序中使用多少本地信息。如果α被设置为1，则不考虑本地信息。如果α为0，QoS值，其对应的用户和服务是在同一个用户服务组中，由本地矩阵因式分解独立预测，没有任何来自全球的信息。也就是说，我们只使用地理上接近的用户和服务的历史调用记录来进行预测。总而言之，利用a来保持全球环境和本地信息之间的良好平衡。为了研究a对我们模型的影响并找到一个最佳的模型，我们将密度从15%调整到30%，步长为5%。

图4和图5向我们展示了在4个不同的矩阵密度设置下，当a的值从0.4到1.0变化时，MAE和NMAE的变化。我们可以看到，在矩阵密度为15%、20%或25%时，当a在0.8左右时，MAE和NMAE都是最低的。这意味着当α=0.8时，我们的分层矩阵分解模型在密度15%、20%或25%时表现最好，而对于密度30%，α=0.9是最合适的选择。

在这一段中，我们将对矩阵密度为15%的条件提出讨论。我们从图中看到，当α为0.4时，MAE和NMAE都很高。当a的值从0.4变化到0.8时，MAE以及NMAE起初急剧下降，但当a接近最佳值时就变得平稳了。这表明太少的全局环境使用会损害我们模型的性能。在开始的时候，增加全局语境的影响会高度提高预测的准确性，但是当模型接近本地信息和全局语境的平衡时，其影响就变得很小了。我们还可以注意到，当a大于0.8时，MAE和NMAE会变大，这告诉我们，对本地信息的忽视会导致性能的下降。当矩阵密度为20%、25%或30%时，其变化趋势和变化原因与我们刚才讨论的相似。



## 5.5 Impact of Parameter $d$



## 5.6 Impact of Matrix Density

