# 算法思路

Collaborative Web Service Quality Prediction via Matrix Factorization with Network Bias



## Introduction

// 总览



## 问题定义

// todo 举例子 

// 描述具体问题

// 为什么一般的矩阵分解方法不行

### 



```
算法部分
1. > 完成具体公式部分，以及符号表，基于相关论文 <
2. 完成小节介绍部分，以及相关论文引用
2. 完成公式描述部分，务必参考相关论文，并进行引用
3. 完成作图部分，务必参考相关论文，并进行引用
4. 完成小节草稿后，进行排版
```

### Baseline

给定一组m个用户和一组n个服务，那么所有用户和服务之间的Qos值可以用一个矩阵$Q \in \mathbb{R}^{m \times n}$来表示，其中的记录$Q_{ij}$表示用户i观察到的服务j的Qos值。显然，考虑到由于高时间成本和巨大的资源开销，用户不可能自己调用所有的Web服务来获得个性化的Qos值。因此，我们通常只有用户和网络服务之间的部分观察，这意味着矩阵$Q$中的许多调用记录是空的。QoS预测的目标是通过利用现有观测中包含的信息来预测这些空条目。

假设有n个用户，和m个服务。一个QoS记录Rij(t)∈Rn×m代表用户ui在时间片t调用服务sj的QoS值。我们用Iij(t)=1表示观察到的条目，Iij(t)=0表示未知条目。那么当前时间片tc的未知条目{Rij(tc)|Iij(tc)=0}应该根据所有历史上观察到的条目{Rij(t)|Iij(t)=1,t∈[1,...,tc]}来预测。

假设有m个用户和n个服务，那么所有用户和服务之间的Qos值可以用一个矩阵$Q \in \mathbb{R}^{m \times n}$来表示。其中，记录 $Q_{ij}$ 表示用户 $i$ 调用服务 $j$ 的Qos值，如果用户 $i$ 调用过服务 $j$，则 $I_{ij}=1$，否则 $I_{ij}=0$。在进行服务质量预测之前，NBMF需要根据观察到的服务质量数据建立一个全局模型。

## matrix factorization model

> 此处可以对Cost项进行详细解释，参照已有素材

MF是预测矩阵中缺失值最流行和有效的方法。矩阵分解使用因子模型来拟合用户服务矩阵进行预测。它将高维度的用户服务评分矩阵分解成两个低维度的特征矩阵来进行预测。这种分解的前提有少量的潜在因素影响用户对 Web 服务的偏好。另外，每个潜在因素对用户在 Web 服务上的体验和偏好有很大的影响，而且所有的潜在特征向量都可以通过统计学习理论来构建。MF模型中最重要的一步是通过构建目标函数来获得两个独立的特征空间。

我们用 Q 表示用户-服务的质量矩阵，并尝试接近 Q。
$$
Q \approx UW^T \tag{1}
$$
其中 $U \in R_{m \times d}$ 表示用户潜在特征矩阵，$W \in R_{n \times d}$ 表示服务潜在特征矩阵。向量 $U_i (1\le i\le m)$ 表示用户潜在特征向量，向量 $W_j (1\le j\le n)$ 表示服务潜在特征向量，他们的维度为d，维度是一个超参数，需要在实验评估中得最为合适的值。

现在，需要估计矩阵 $U$ 和 $W$ 的值。利用如下目标函数使 $U$ 和 $W$ 对原始质量矩阵 $Q$ 进行近似拟合，最小化公式如下：
$$
L = min_{U,W}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - U_iW_j^T)^2 \tag{2}
$$
其中 $I_{ij}$ 是指示函数，如果用户 $u$ 调用过服务 $w$，则返回1，否则返回0。为了避免过度拟合得到最优的 $U$ 和 $W$ 逼近原始矩阵 $Q$，我们加入了两个与 $U$ 和 $I$ 相关的正则项：
$$
L = min_{U,W}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - U_iW_j^T)^2 + \frac{\lambda_1}{2}\Vert U\Vert^2_F + \frac{\lambda_2}{2}\Vert W\Vert^2_F \tag{3}
$$
其中$\Vert \cdot \Vert$ 表示 Frobenius 范数[12.26.01]， $\lambda_1$ 和 $\lambda_2$ 两个参数控制正则化程度。目标函数 L 使用二次正则项来最小化平方误差和。因为他不是凸的，所以设计一个算法来找到全局最小是不现实的。我们选择采用随机梯度下降法求解$U$ 和 $W$ 的近似最优解。
$$
U'_i = U_i - \alpha_1 \frac{\partial L}{\partial U_i}
\\W'_j = W_j - \alpha_2 \frac{\partial L}{\partial W_j} \tag{4}
$$
其中 $\alpha_1 > 0$ 和 $\alpha_2 > 0$ 表示学习速率。 

$$
U'_i = U_i + \alpha_1 [(Q_{ij} - U_iW_j^T)W_j - \lambda_1U_i]
\\W'_j = W_j + \alpha_2 [((Q_{ij} - U_iW_j^T)U_i - \lambda_2W_j)] \tag{4}
$$


## Baseline-based matrix factorization

MF模型试图捕捉用户和服务之间的交互作用，正是这些交互作用产生了不同的质量评分。然而，实际上大部分观察到的评分值要么和用户相关，要么和服务相关，要么和用户与服务之间的网络距离相关，而与用户和服务之间的交互作用无关。比如，某些用户因为所在地的高速带宽，而偏向于给出更高的质量评分；某些服务因为所在地的高速带宽，而偏向于得到更高的质量评分；某些用户因为和目标服务有着相近的网络距离，而偏向于给出更高的质量评分。

我们将这些与用户-服务交互作用无关的因子称为偏置，并把偏置封装到基准预测中。由于这些基准预测值在观察到的评分中占很大比例，因此对他们进行准确的建模就显得至关重要。这样的建模方法把真正代表用户-服务交互作用的那部分数据隔离开来，而把这部分数据放到更适合用户偏好的模型中。按照以上思路，we propose an NIMF approach, which makes the best utilization of both the local information of similar users and the global information of all the available Qos values in the  user-item matrix to achieve better prediction accuracy. Our approach is designed as a two-phase process. （the defination and notation, or overview）



### Definiton and Notation

参考论文

```
Graph Neural Networks for Social Recommendation
```



### Overview

![image-20220128180407182](image-20220128180407182.png)



参考论文：

```
Location-Based Web Service Qos Prediction via Preference Progagation to Address Cold Start Problem
```



###  Network Baseline（Regional  Baseline）

基准预测的设计思想来源于线性回归模型，如果我们将评分看作是一个连续的值而不是离散的值，那么就可以借助线性回归思想来预测目标用户对某服务的评分。传统的基线模型使用如下步骤来预测评分，先计算所有服务的平均评分，即全局平均分 $\mu$，之后分别计算每个用户 $i$ 所给出的评分普遍高于或低于其他用户的偏置值 $\bold{b}_i$，以及每个服务 $j$ 所接受的评分普遍高于或低于其他服务的偏置值 $\bold{p}_j$，传统基线模型的评分预测公式如下：
$$
\hat{Q}_{ij} = \mu + \bold{b}_i + \bold{p}_j \tag{5}
$$
然而传统的基线模型仅仅考虑到了用户偏置和服务偏置，并未考虑到用户和服务的网络距离。在服务预测的过程中，用户对服务的调用往往涉及到两个区域的通信，而区域与区域间网络距离的差异会很大程度上影响用户的质量评分。比如，相同的服务部署在不同的区域，给用户带来的体验是完全不同的；同理，相同的用户在不同的区域调用相同的服务，用户所观察到的服务质量也是完全不同的。

为了全方位的考虑与用户-物品交互作用无关的因子，我们提出了基于网络的基准预测模型。基于网络的基准预测模型对传统基准预测模型进行改进，不但考虑了用户侧的网络偏置和服务侧的网络偏置，还将考虑用户与服务间的网络距离所带来的评分影响。改进后的评分预测过程如下，设 $x$ 为 用户 $i$ 所在区域，$y$ 为服务 $j$ 所在区域，先计算区域 $x$ 对区域 $y$ 的平均评分 $G_{xy}$，然后结合用户 $i$ 和服务 $j$ 对其所属区域的网络偏置，即可得到考虑网络距离的基准预测值。
$$
\hat{Q}_{ij} = G_{xy} + \bold{b}_i + \bold{p}_j \tag{6}
$$
其中 $\bold{b}_i$ 表示用户 $i$ 对其所属区域的网络偏置，$\bold{p}_j$ 表示服务 $j$ 对其所属区域的网络偏置。对于所有区域间的评分矩阵 $G$ 是直接能计算出来的
$$
G_{xy} = \frac{\sum_{i\in M(x),j\in M(y)}I_{ij}Q_{ij}}{\sum_{i\in M(x),j\in M(y)}I_{ij}} \tag{7}
$$
其中， $I_{ij}$ 是指示函数，如果用户 $i$ 调用过服务 $j$，则返回1，否则返回0，$M(x)$ 表示所属区域为 $x$ 的用户集合，$M(y)$ 表示所属区域为 $y$ 的服务集合。根据研究的粒度和数据集的信息，区域的级别可能会有所不同。在本文中，我们将区域的级别视为国家层面，因为Zheng[12.29.01]解释了服务的质量评价可能会根据用户所在国家和服务所在位置而改变。

现在，问题的关键在于需要估计向量 $\bold{b}$ 和向量 $\bold{p}$ 的值，利用如下目标函数使 $\bold{b}$ 和 $\bold{p}$ 对原始质量矩阵 $Q$ 进行近似拟合，最小化公式如下
$$
L = min_{\bold{b},\bold{p}}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - G_{xy} - \bold{b}_i - \bold{p}_j)^2 \tag{8}
$$
为了避免过度拟合得到最优的 $\bold{b}$ 和 $\bold{p}$ 逼近原始矩阵 $Q$，我们加入了两个与 $\bold{b}$ 和 $\bold{p}$ 相关的正则项：
$$
L = min_{\bold{b},\bold{p}}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - \mu - \bold{b}_i - \bold{p}_j)^2 + \frac{\lambda_1}{2}\Vert \bold{b}\Vert^2_F + \frac{\lambda_2}{2}\Vert \bold{p}\Vert^2_F\tag{9}
$$
其中$\lambda_1$ 和 $\lambda_2$ 两个参数控制正则化程度。目标函数 L 使用二次正则项来最小化平方误差和。因为他不是凸的，所以设计一个算法来找到全局最小是不现实的。我们选择采用随机梯度下降法求解$U$ 和 $W$ 的近似最优解。
$$
\bold{b}'_i = \bold{b}_i - \beta_1 \frac{\partial L}{\partial \bold{b}_i}
\\\bold{p}'_j = \bold{p}_j - \beta_2 \frac{\partial L}{\partial \bold{p}_j} \tag{10}
$$
其中 $\beta_1 > 0$ 和 $\beta_2 > 0$ 表示学习速率。 



为了全方位的考虑与用户服务交互作用无关的因子，我们在上一节中提出了基于网络的基准预测模型。在本节中，我们使用 $nbl(i,j)$ 表示特定用户 $i$ 对特定服务 $j$ 的基准预测值。
$$
\begin{split}
nbl(i, j) &=G_{xy} + \bold{b}_i + \bold{p}_j
\end{split}
$$

### Baseline-based Matrix Factorization

仅靠基准预测并不能产生个性化推荐，因为他忽略了用户和物品之间的所有交互。在某种意义上来说，它只是抓住了与建立推荐不是很相关的那部分数据。为了把真正代表用户服务交互作用的那部分数据考虑进来，我们需要融合一种更加适合用户偏好的模型，即矩阵分解模型。

矩阵分解模型把用户和服务两方面的信息映射到一个维度为d的联合隐语义空间中，因此，用户服务的交互作用可以由该空间中的内积来建模，加上之前提到的只依赖于与用户-物品交互作用无关因子的基准预测，可以得到最终的预测评分。
$$
\begin{split}
\hat {Q}_{ij} &= nbl(i, j) +{U_iW_j^T}
\end{split}
$$
其中，每一个用户 $i$ 都与一个 d 维向量 $U_i$ 相关联，每一个服务 $j$ 都与一个 d 维向量 $Wj$ 相关联。给定一个服务 $j$，$W_j$ 向量的每个维度值的大小代表了该服务具备这些因子的程度。给定一个用户 $i$，$U_i$ 向量的每个维度值代表了用户对这些因子的偏好程度，这些值的大小反映了用户对这些因子的积极或者消极的评价。点积 $U_iW_j^T$ 记录了用户和服务之间的交互，也就是用户对服务的总体兴趣。函数 $nbl(i, j)$ 代表特定用户 $i$ 对特定服务 $j$ 的基准预测值。

现在，需要估计矩阵 $U$ 和 $W$ 的值。利用如下目标函数使 $U$ 和 $W$ 对原始质量矩阵 $Q$ 进行近似拟合，最小化公式如下：
$$
L = min_{U,W}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - nbl(i, j) - U_iW_j^T)^2 + \frac{\lambda_1}{2}\Vert {U}\Vert^2_F + \frac{\lambda_2}{2}\Vert {W}\Vert^2_F\tag{9}
$$
基于网络基线的矩阵分解法既考虑了用户服务交互作用相关的因子，又考虑到了用户服务交互作用无关的因子。但是矩阵分解方法依旧存在其局限性，矩阵分解不方便加入用户上下文和服务上下文的相关特征，这使得矩阵分解丧失了利用很多有效信息的机会。





### Baseline based Similarity Computation

为了在矩阵分解中考虑充分的邻域信息，越来越多的研究者开始将用户相似度计算和服务相似度计算与矩阵分解模型相结合。但是传统的相似度计算方法并没有正确而且系统的解决一个主要的问题，服务的质量评价可能会根据用户所在国家和服务所在位置而改变。所以，本文基于pcc提出了一种考虑网络偏置的改进算法，分别用于用户相似度的计算和服务相似度的计算。

* 用户相似度

用户相似度计算的基本思想是，相似的用户对相同的物品有相似的评价。一般情况下，我们使用 Pearson 相关系数来衡量用户 $i$ 和 用户 $k$ 之间评分向量的相似程度 $sim(i, k)$。由于许多评分未知，两个用户之间或许只有几个公共的评分商品，我们使用集合 $W(i, k)$ 表示用户 $i$ 和用户 $k$ 共同做出评分的服务序号集合，仅在这个集合的物品上计算相关系数。为了在计算过程中考虑到网络偏置对用户真实评分的影响，本文提出用基准预测值来修正特定用户和特定服务的偏差。因此，用户相似度计算公式如下所示：
$$
sim(i, k) = \cfrac{\sum_{j\in W(i, k)}(Q_{ij} - nbl(i, j))(Q_{kj} - nbl(k, j))}{\sqrt{\sum_{j\in W(i,k)}(Q_{ij} - nbl(i, j))^2 \cdot \sum_{j\in W(i,k)}(Q_{kj} - nbl(k, j))^2 }}
$$
从这个定义中可以看出，两个用户 $i$ 与 $k$ 的相似度计算结果在[-1, 1]之间，其中1表示负相关, 1表示正相关。

计算当前用户与其他所有用户的相似度后，根据相似度的排名可以识别出一组Top-k相似的用户。在实践中，一个用户只能有数量有限的类似的用户。传统的Top-k算法忽略了以这一个问题，仍然包含了相似度为负值的不同用户，这将极大地影响预测精度。在我们的方法中，我们排除了具有负相关性的不同用户。因此，对于特定用户 $i$ 一组类似的用户 $N(i)$ 可以用以下公式来识别
$$
N(i) = \{k|k\in {\rm Top\hbox{-}K}(i), sim(i,k) > 0,i \ne k\}
$$
其中，${\rm Top\hbox{-}K}(i)$ 为与当前用户 $i$ 相似的 Top-k 用户的集合，$sim(i,k)$ 为用户 $i$ 与用户 $k$ 的相似度值，可以通过 (1)式计算得到。注意，Top -k关系是不对称的。用户 $k$ 在用户 $i$ 的 Top-K 邻居中并不意味着用户 $i$ 也在用户 $k$ 的Top-K邻居中。有了用户侧的邻居信息，我们可以设计结合用户邻域的矩阵分解模型。



* 服务相似度

服务相似度计算的基本思想是，同一位用户对相似的服务评价也是相似的。同样的，我们使用 Pearson 相关系数来衡量用户对服务 $j$ 和 服务 $c$ 进行评分的相似性趋势 $sim(j, k)$。我们使用集合 $U(j, c)$ 表示同时对服务 $j$ 和服务 $c$ 评分的用户序号集合，函数 $nbl(i,j)$ 表示特定用户 $i$ 对特定服务 $j$ 的基准预测值。服务相似度计算公式如下：
$$
sim(j, k) = \cfrac{\sum_{i\in U(j, k)}(Q_{ij} - nbl(i, j))(Q_{ik} - nbl(i, k))}{\sqrt{\sum_{i\in U(j,k)}(Q_{ij} - nbl(i, j))^2 \cdot \sum_{i\in U(j,k)}(Q_{ik} - nbl(i, k))^2 }}
$$
两个服务的相似度计算结果在[-1, 1]之间。当计算出所有用户与当前用户的相似度之后，我们可以获取出其中的topk相似的用户。我们的方法排序了具有负相关性的不同服务。对于特定服务 $j$ 的相似服务 $N(j)$ 可以用以下公式来识别
$$
N(i) = \{k|k\in {\rm Top\hbox{-}K}(i), sim(i,k) > 0,i \ne k\}
$$
在获取了邻域信息之后，我们可以设计结合了用户邻域和服务邻域的矩阵分解模型。



### Neighborhood-Integrated Matrix Factorization

矩阵分解模型通常利用评分矩阵中的全局信息来预测缺失值，这种方法可以有效的估计与用户和服务同时相关的整体结构。然而，矩阵分解模型在检测紧密相关的一组用户或服务之间的强关联方面表现很差，而这恰恰是邻域模型更加擅长的地方。为了同时对全局信息和局部信息加以利用，在本节中，我们详细讨论了如何将用户邻域信息和服务邻域信息作为正则项来改进矩阵分解模型。

* 用户邻域模型

在用户的邻居中，若存在某个邻居用户比其他邻居用户具有更好的相似度，那么认为该邻居用户可以共享更多的潜在信息。因此，我们应该根据特定用户与邻居用户的相似程度来给这些邻居用户分配不同的权重。为了重新进行权值分配，我们首先计算用户 $i$ 与邻居用户 $k$ 之间的局部相似性 $S_{ik}$
$$
S_{ik} = \cfrac{sim(i, k)}{\sum_{k \in N(i)}sim(i, k)}
$$
其中，$sim(i,k)$ 表示用户 $i$ 与用户 $k$ 的全局相似度，$N(i)$ 为用户 $i$ 的Top-k相似用户的集合，我们对用户 $k$  的 全局相似度进行归一化操作，即可得到用户 $k$ 的局部相似度 $S_{ik}$。

由于用户倾向于与其邻居共享类似的服务调用体验，用户与其邻居用户的特征向量的差异应该很小。结合公式3中邻居用户的局部相似性计算方法，我们提出了一个基于用户领域的正则化公式来对相似用户之间的强关联性加以限制。
$$
min \Vert U_i - \sum_{k\in N(i)}S_{ik}U_k \Vert ^2_F
$$

* 服务邻域模型

在服务的邻居中，如果存在某个邻居服务比其他邻居服务拥有更好的相似度，则认为该邻居服务可以共享更多的潜在信息。因此，我们应该根据特定服务与其邻居服务之间的相似程度来给这些邻居服务分配不同的权重。我们使用 $S_{ik}$ 来表示用户 $i$ 与邻居用户 $k$ 之间的局部相似程度。
$$
S_{jk} = \cfrac{sim(j, k)}{\sum_{k \in N(j)}sim(j, k)}
$$
其中，$sim(j, k)$ 表示服务$i$ 与服务 $k$ 的全局相似度，$N(j)$ 为服务 $j$ 的Top-k相似服务的集合，我们对服务 $k$ 的全局相似度进行归一化操作，即可得到服务 $k$ 的局部相似度 $S_{jk}$。

由于服务倾向于与其邻居服务共享类似的用户评分体验，服务与其邻居服务的特征向量的差异应该很小。结合公式5中邻居服务的局部相似性计算方法，我们提出了一个基于服务领域的正则化公式来对相似服务之间的强关联性加以限制。
$$
min \Vert W_j - \sum_{k\in N(j)}S_{jk}W_k \Vert ^2_F
$$

* 矩阵分解

我们将基于用户邻域和基于服务邻域的正则项添加到我们的第二个提议的方法中，以修改基于网络基线的矩阵分解模型，最小化公式如下：
$$
L = min_{\bold{b},\bold{p}}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - nbl(i, j) - U_iW_j^T)^2 + \frac{\lambda_1}{2}\Vert {U}\Vert^2_F + \frac{\lambda_2}{2}\Vert {W}\Vert^2_F\tag{9}
$$

梯度下降





### prediction



## Experimental



## Related work



## Conclusion and future work

