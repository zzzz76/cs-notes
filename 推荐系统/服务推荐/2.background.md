# 2 Background



## 2.1 Problem Definition

> 参考：CMF、CNMF、GNN

给定一组m个用户和一组n个服务，那么所有用户和服务之间的Qos值可以用一个矩阵$Q \in \mathbb{R}^{m \times n}$来表示，其中的记录$Q_{ij}$表示用户i观察到的服务j的Qos值。显然，考虑到由于高时间成本和巨大的资源开销，用户不可能自己调用所有的Web服务来获得个性化的Qos值。因此，我们通常只有用户和网络服务之间的部分观察，这意味着矩阵$Q$中的许多调用记录是空的。QoS预测的目标是通过利用现有观测中包含的信息来预测这些空条目。



## 2.2 Matrix Factorization

在矩阵分解中，低维度的特征矩阵试图通过描述用户和服务在各个因子上的特征来解释Qos值。例如，服务隐向量的每个维度值的大小代表了该服务具备这些因子的程度，用户隐向量的每个维度值的大小代表了用户对这些因子的感知程度，用户隐向量和服务隐向量的点积代表了用户和服务之间的交互作用，也就是用户调用服务的Qos值。

MF是预测矩阵中缺失值最流行和有效的方法。矩阵分解使用因子模型来拟合用户服务矩阵进行预测。它将高维度的用户服务评分矩阵分解成两个低维度的特征矩阵来进行预测。这种分解的前提有少量的潜在因素影响用户对 Web 服务的偏好。另外，每个潜在因素对用户在 Web 服务上的体验和偏好有很大的影响，而且所有的潜在特征向量都可以通过统计学习理论来构建。MF模型中最重要的一步是通过构建目标函数来获得两个独立的特征空间。

我们用 Q 表示用户-服务的质量矩阵，并尝试接近 Q。
$$
Q \approx UW^T \tag{1}
$$
其中 $U \in R_{m \times d}$ 表示用户潜在特征矩阵，$W \in R_{n \times d}$ 表示服务潜在特征矩阵。向量 $U_i (1\le i\le m)$ 表示用户潜在特征向量，向量 $W_j (1\le j\le n)$ 表示服务潜在特征向量，他们的维度为d，维度是一个超参数，需要在实验评估中得最为合适的值。

现在，需要估计矩阵 $U$ 和 $W$ 的值。利用如下目标函数使 $U$ 和 $W$ 对原始质量矩阵 $Q$ 进行近似拟合，最小化公式如下：
$$
L = min_{U,W}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - U_iW_j^T)^2 \tag{2}
$$
其中 $I_{ij}$ 是指示函数，如果用户 $u$ 调用过服务 $w$，则返回1，否则返回0。为了避免过度拟合得到最优的 $U$ 和 $W$ 逼近原始矩阵 $Q$，我们加入了两个与 $U$ 和 $I$ 相关的正则项：
$$
L = min_{U,W}\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{n}I_{ij}(Q_{ij} - U_iW_j^T)^2 + \frac{\lambda_1}{2}\Vert U\Vert^2_F + \frac{\lambda_2}{2}\Vert W\Vert^2_F \tag{3}
$$
其中$\Vert \cdot \Vert$ 表示 Frobenius 范数[12.26.01]， $\lambda_1$ 和 $\lambda_2$ 两个参数控制正则化程度。目标函数 L 使用二次正则项来最小化平方误差和。因为他不是凸的，所以设计一个算法来找到全局最小是不现实的。我们选择采用随机梯度下降法求解$U$ 和 $W$ 的近似最优解。
$$
U'_i = U_i - \alpha_1 \frac{\partial L}{\partial U_i}
\\W'_j = W_j - \alpha_2 \frac{\partial L}{\partial W_j} \tag{4}
$$
其中 $\alpha_1 > 0$ 和 $\alpha_2 > 0$ 表示学习速率。 

$$
U'_i = U_i + \alpha_1 [(Q_{ij} - U_iW_j^T)W_j - \lambda_1U_i]
\\W'_j = W_j + \alpha_2 [((Q_{ij} - U_iW_j^T)U_i - \lambda_2W_j)] \tag{4}
$$

